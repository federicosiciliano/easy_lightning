{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2nRCG0Q8347G"
   },
   "source": [
    "# Preparation stuff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c81IM9YmWpCp"
   },
   "source": [
    "## Connect to Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1686658044012,
     "user": {
      "displayName": "Federico Siciliano",
      "userId": "13460778358604487896"
     },
     "user_tz": -120
    },
    "id": "EoEPCwJGdpz_"
   },
   "outputs": [],
   "source": [
    "connect_to_drive = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 31338,
     "status": "ok",
     "timestamp": 1686658075342,
     "user": {
      "displayName": "Federico Siciliano",
      "userId": "13460778358604487896"
     },
     "user_tz": -120
    },
    "id": "QgLWUVMAWpCq",
    "outputId": "539a36c4-47bc-435a-ebb0-d59c874000c6"
   },
   "outputs": [],
   "source": [
    "#Run command and authorize by popup --> other window\n",
    "if connect_to_drive:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/gdrive', force_remount=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SzMilQQcEL-w"
   },
   "source": [
    "## Install packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if connect_to_drive:\n",
    "    #Install FS code\n",
    "    !pip install  --upgrade --force-reinstall git+https://github.com/federicosiciliano/easy_lightning.git\n",
    "\n",
    "    !pip install pytorch_lightning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "llsyZg59yyiX"
   },
   "source": [
    "## IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 5232,
     "status": "ok",
     "timestamp": 1686658109562,
     "user": {
      "displayName": "Federico Siciliano",
      "userId": "13460778358604487896"
     },
     "user_tz": -120
    },
    "id": "U0GsBSD6yz9y"
   },
   "outputs": [],
   "source": [
    "#Put all imports here\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mnSShc_Yy4lr"
   },
   "source": [
    "## Define paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1686658109563,
     "user": {
      "displayName": "Federico Siciliano",
      "userId": "13460778358604487896"
     },
     "user_tz": -120
    },
    "id": "WRYc5NEeyjQ8"
   },
   "outputs": [],
   "source": [
    "#every path should start from the project folder:\n",
    "project_folder = \"../\"\n",
    "if connect_to_drive:\n",
    "    project_folder = \"/content/gdrive/Shareddrives/<SharedDriveName>\" #Name of SharedDrive folder\n",
    "    #project_folder = \"/content/gdrive/MyDrive/<MyDriveName>\" #Name of MyDrive folder\n",
    "\n",
    "#Config folder should contain hyperparameters configurations\n",
    "cfg_folder = os.path.join(project_folder,\"cfg\")\n",
    "\n",
    "#Data folder should contain raw and preprocessed data\n",
    "data_folder = os.path.join(project_folder,\"data\")\n",
    "raw_data_folder = os.path.join(data_folder,\"raw\")\n",
    "processed_data_folder = os.path.join(data_folder,\"processed\")\n",
    "\n",
    "#Source folder should contain all the (essential) source code\n",
    "source_folder = os.path.join(project_folder,\"src\")\n",
    "\n",
    "#The out folder should contain all outputs: models, results, plots, etc.\n",
    "out_folder = os.path.join(project_folder,\"out\")\n",
    "img_folder = os.path.join(out_folder,\"img\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B4fhGkp14CSb"
   },
   "source": [
    "## Import own code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 3705,
     "status": "ok",
     "timestamp": 1686658113259,
     "user": {
      "displayName": "Federico Siciliano",
      "userId": "13460778358604487896"
     },
     "user_tz": -120
    },
    "id": "LrX3FM7szllL"
   },
   "outputs": [],
   "source": [
    "#To import from src:\n",
    "\n",
    "#attach the source folder to the start of sys.path\n",
    "sys.path.insert(0, project_folder)\n",
    "\n",
    "#import from src directory\n",
    "# from src import ??? as additional_module\n",
    "import easy_rec as additional_module #REMOVE THIS LINE IF IMPORTING OWN ADDITIONAL MODULE\n",
    "\n",
    "import easy_exp, easy_rec, easy_torch #easy_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DIslF_wh31z2"
   },
   "source": [
    "# MAIN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o9gCiPA9dp0H"
   },
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "1oW5REUm4GC8"
   },
   "outputs": [],
   "source": [
    "cfg = easy_exp.cfg.load_configuration(\"config_rec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ratings data already exists. Skip pre-processing\n",
      "Filtering by minimum number of users per item: 5\n",
      "Filtering by minimum number of items per user: 5\n",
      "Densifying index\n",
      "Splitting: leave_n_out\n"
     ]
    }
   ],
   "source": [
    "data_params = deepcopy(cfg[\"data_params\"])\n",
    "data_params[\"data_folder\"] = raw_data_folder\n",
    "\n",
    "data, maps = easy_rec.data_generation_utils.preprocess_dataset(**data_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Save user and item mappings\n",
    "# with open(os.path.join(processed_data_folder,\"user_map.csv\"), \"w\") as f_user:\n",
    "#     w = csv.writer(f_user)\n",
    "#     w.writerows(maps['uid'].items())\n",
    "\n",
    "# with open(os.path.join(processed_data_folder,\"item_map.csv\"), \"w\") as f_item:\n",
    "#     w = csv.writer(f_item)\n",
    "#     w.writerows(maps['sid'].items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = easy_rec.rec_torch.prepare_rec_datasets(data,**data_params[\"dataset_params\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collator_params = deepcopy(cfg[\"data_params\"][\"collator_params\"])\n",
    "collator_params[\"num_items\"] = np.max(list(maps[\"sid\"].values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# app = collator_params.get(\"negatives_distribution\",None)\n",
    "# if app is not None:\n",
    "#     if app == \"popularity\":\n",
    "#         collator_params[\"negatives_distribution\"] = easy_rec.data_generation_utils.get_popularity_items(datasets[\"train\"], collator_params[\"num_items\"])\n",
    "#     elif app not in [\"uniform\",\"dynamic\"]:\n",
    "#         raise ValueError(\"Invalid negatives distribution\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collators = easy_rec.rec_torch.prepare_rec_collators(**collator_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader_params = deepcopy(cfg[\"model\"][\"loader_params\"])\n",
    "loaders = easy_rec.rec_torch.prepare_rec_data_loaders(datasets, **loader_params, collate_fn=collators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_model_params = deepcopy(cfg[\"model\"][\"rec_model\"])\n",
    "rec_model_params[\"num_items\"] = np.max(list(maps[\"sid\"].values()))\n",
    "rec_model_params[\"num_users\"] = np.max(list(maps[\"uid\"].values()))\n",
    "rec_model_params[\"lookback\"] = data_params[\"collator_params\"][\"lookback\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    }
   ],
   "source": [
    "main_module = easy_rec.rec_torch.create_rec_model(**rec_model_params)#, graph=easy_rec.data_generation_utils.get_graph_representation(data[\"train_sid\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment already found: True ----> The experiment id is: VBdAdVbFguHeB1Ic\n"
     ]
    }
   ],
   "source": [
    "exp_found, experiment_id = easy_exp.exp.get_set_experiment_id(cfg)\n",
    "print(\"Experiment already found:\", exp_found, \"----> The experiment id is:\", experiment_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Find \"original\" implementation:\n",
    "# # ...\n",
    "\n",
    "# keys_to_change = {\"model.rec_model.seed\": 42}\n",
    "# orig_cfg = deepcopy(cfg)\n",
    "# for k,v in keys_to_change.items():\n",
    "#     orig_cfg[k] = 42\n",
    "\n",
    "# orig_exp_found, orig_experiment_id = easy_exp.exp.get_experiment_id(orig_cfg)\n",
    "# print(\"Experiment already found:\", orig_exp_found, \"----> The experiment id is:\", orig_experiment_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if exp_found: exit() #TODO: make the notebook/script stop here if the experiment is already found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "Seed set to 42\n",
      "Seed set to 42\n",
      "GPU available: True (mps), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/trainer/setup.py:177: GPU available but not used. You can set it by doing `Trainer(accelerator='gpu')`.\n",
      "Seed set to 42\n",
      "Seed set to 42\n",
      "Seed set to 42\n",
      "Seed set to 42\n",
      "Seed set to 42\n",
      "Seed set to 42\n",
      "Seed set to 42\n",
      "Seed set to 42\n",
      "Seed set to 42\n",
      "Seed set to 42\n",
      "Seed set to 42\n",
      "Seed set to 42\n",
      "Seed set to 42\n",
      "Seed set to 42\n",
      "Seed set to 42\n",
      "Seed set to 42\n",
      "Seed set to 42\n",
      "Seed set to 42\n",
      "Seed set to 42\n",
      "Seed set to 42\n",
      "Seed set to 42\n",
      "Seed set to 42\n",
      "Seed set to 42\n"
     ]
    }
   ],
   "source": [
    "model_params = deepcopy(cfg[\"model\"])\n",
    "\n",
    "trainer_params = easy_torch.preparation.prepare_experiment_id(model_params[\"trainer_params\"], experiment_id)\n",
    "\n",
    "#dynamic_negatives_index = [i for i, x in enumerate(trainer_params[\"callbacks\"]) if \"DynamicNegatives\" in x][0]\n",
    "#trainer_params[\"callbacks\"][dynamic_negatives_index][\"DynamicNegatives\"][\"dataloader\"] = loaders[\"train\"]\n",
    "\n",
    "# Prepare callbacks and logger using the prepared trainer_params\n",
    "trainer_params[\"callbacks\"] = easy_torch.preparation.prepare_callbacks(trainer_params, additional_module.callbacks)\n",
    "trainer_params[\"logger\"] = easy_torch.preparation.prepare_logger(trainer_params)\n",
    "\n",
    "# Prepare the trainer using the prepared trainer_params\n",
    "trainer = easy_torch.preparation.prepare_trainer(**trainer_params)\n",
    "\n",
    "model_params[\"loss\"] = easy_torch.preparation.prepare_loss(model_params[\"loss\"], additional_module.losses)\n",
    "\n",
    "# Prepare the optimizer using configuration from cfg\n",
    "model_params[\"optimizer\"] = easy_torch.preparation.prepare_optimizer(**model_params[\"optimizer\"])\n",
    "\n",
    "# Prepare the metrics using configuration from cfg\n",
    "# num_negatives = {split_name:[x] for split_name,x in data_params[\"collator_params\"][\"num_negatives\"].items()}\n",
    "# num_negatives[\"val\"] += num_negatives[\"test\"] #cause using test as val just to get metrics\n",
    "# model_params[\"metrics\"] = additional_module.metrics.prepare_rank_corrections(model_params[\"metrics\"], num_negatives = num_negatives, num_items = rec_model_params[\"num_items\"])\n",
    "model_params[\"metrics\"] = easy_torch.preparation.prepare_metrics(model_params[\"metrics\"], additional_module.metrics)\n",
    "\n",
    "# Create the model using main_module, loss, and optimizer\n",
    "model = easy_torch.process.create_model(main_module, **model_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the emission tracker using configuration from cfg\n",
    "#tracker = easy_torch.preparation.prepare_emission_tracker(**cfg[\"model\"][\"emission_tracker\"], experiment_id=experiment_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the flops profiler using configuration from cfg\n",
    "#profiler = easy_torch.preparation.prepare_flops_profiler(model=model, **cfg[\"model\"][\"flops_profiler\"], experiment_id=experiment_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jttfzSb5Oezv"
   },
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#easy_torch.process.test_model(trainer, model, loaders, test_key=[\"train\",\"val\",\"test\"]) #, tracker=tracker, profiler=profiler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "SNGT89Tbdp0K"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /Users/federicosiciliano/Desktop/Py_utils/easy_lightning_development/easy_rec/out/models/prova/VBdAdVbFguHeB1Ic exists and is not empty.\n",
      "\n",
      "  | Name        | Type                        | Params | Mode \n",
      "--------------------------------------------------------------------\n",
      "0 | main_module | GRU4Rec                     | 249 K  | train\n",
      "1 | loss        | SequentialBCEWithLogitsLoss | 0      | train\n",
      "2 | metrics     | RobustModuleDict            | 0      | train\n",
      "--------------------------------------------------------------------\n",
      "249 K     Trainable params\n",
      "0         Non-trainable params\n",
      "249 K     Total params\n",
      "0.998     Total estimated model params size (MB)\n",
      "39        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (8) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|██████████| 8/8 [00:01<00:00,  5.26it/s, v_num=2]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=20` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|██████████| 8/8 [00:01<00:00,  5.24it/s, v_num=2]\n"
     ]
    }
   ],
   "source": [
    "# Train the model using the prepared trainer, model, and data loaders\n",
    "easy_torch.process.train_model(trainer, model, loaders, val_key=[\"val\",\"test\"]) #tracker=tracker, profiler=profiler, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 8/8 [00:00<00:00, 14.63it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       test_MAP_@10        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">   0.011339527554810047    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       test_MAP_@20        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">   0.009120567701756954    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">        test_MAP_@5        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">   0.013460587710142136    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       test_MRR_@10        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.03370954096317291    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       test_MRR_@20        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.03667048364877701    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">        test_MRR_@5        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.03059384785592556    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       test_NDCG_@10       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.04464862868189812    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       test_NDCG_@20       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.05556769669055939    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       test_NDCG_@5        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">   0.037101712077856064    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">    test_Precision_@10     </span>│<span style=\"color: #800080; text-decoration-color: #800080\">   0.008059385232627392    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">    test_Precision_@20     </span>│<span style=\"color: #800080; text-decoration-color: #800080\">   0.006203605327755213    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">     test_Precision_@5     </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.01145281083881855    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">      test_Recall_@10      </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.08059384673833847    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">      test_Recall_@20      </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.1240721121430397     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">      test_Recall_@5       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.0572640523314476     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.5068372488021851     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m      test_MAP_@10       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  0.011339527554810047   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m      test_MAP_@20       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  0.009120567701756954   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m       test_MAP_@5       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  0.013460587710142136   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m      test_MRR_@10       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.03370954096317291   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m      test_MRR_@20       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.03667048364877701   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m       test_MRR_@5       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.03059384785592556   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m      test_NDCG_@10      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.04464862868189812   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m      test_NDCG_@20      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.05556769669055939   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m      test_NDCG_@5       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  0.037101712077856064   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m   test_Precision_@10    \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  0.008059385232627392   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m   test_Precision_@20    \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  0.006203605327755213   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m    test_Precision_@5    \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.01145281083881855   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m     test_Recall_@10     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.08059384673833847   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m     test_Recall_@20     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.1240721121430397    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m     test_Recall_@5      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.0572640523314476    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.5068372488021851    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "easy_torch.process.test_model(trainer, model, loaders) #, tracker=tracker, profiler=profiler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution completed.\n",
      "######################################################################\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Save experiment and print the current configuration\n",
    "easy_exp.exp.save_experiment(cfg)\n",
    "\n",
    "# Print completion message\n",
    "print(\"Execution completed.\")\n",
    "print(\"######################################################################\")\n",
    "print()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "2nRCG0Q8347G",
    "c81IM9YmWpCp",
    "4vggorg-dp0E",
    "o9gCiPA9dp0H",
    "IqoE-m8ndp0I"
   ],
   "name": "",
   "version": ""
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
